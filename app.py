#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
AIæœ‰å£°æ•…äº‹åº”ç”¨

è¯¥åº”ç”¨ç»“åˆLLMä¸è¯­éŸ³åˆæˆæŠ€æœ¯ï¼Œå¯ä»¥æ ¹æ®ç”¨æˆ·æä¾›çš„æƒ…èŠ‚ç”Ÿæˆæ•…äº‹ï¼Œ
å¹¶ä½¿ç”¨ç”¨æˆ·è‡ªå·±çš„å£°éŸ³è¿›è¡Œè®²è¿°ã€‚
"""

import os
import sys
import time
import tempfile
import shutil
from typing import Tuple, List, Optional, Generator

import torch
import torchaudio
import numpy as np
import gradio as gr
from openai import OpenAI
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# æ·»åŠ CosyVoiceè·¯å¾„åˆ°ç³»ç»Ÿè·¯å¾„
COSYVOICE_PATH = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'CosyVoice')
sys.path.append(COSYVOICE_PATH)
sys.path.append(os.path.join(COSYVOICE_PATH, 'third_party', 'Matcha-TTS'))

# å¯¼å…¥CosyVoiceæ¨¡å—
try:
    from cosyvoice.cli.cosyvoice import CosyVoice2
    from cosyvoice.utils.file_utils import load_wav
    print("æˆåŠŸå¯¼å…¥CosyVoiceæ¨¡å—")
except ImportError as e:
    print(f"é”™è¯¯: æ— æ³•å¯¼å…¥CosyVoiceæ¨¡å—: {e}")
    print(f"è¯·ç¡®ä¿å·²å…‹éš†CosyVoiceåº“åˆ°: {COSYVOICE_PATH}")
    print("å…‹éš†å‘½ä»¤: git clone --recursive https://github.com/FunAudioLLM/CosyVoice.git")
    sys.exit(1)

# å…¨å±€å˜é‡
OPENAI_API_KEY = os.getenv("API_KEY", "lm-studio")
OPENAI_BASE_URL = os.getenv("BASE_URL", "http://localhost:1234/v1")
OPENAI_MODEL_NAME = os.getenv("MODEL_NAME", "qwen2.5-14b-instruct-1m")
COSYVOICE_MODEL_PATH = os.path.join(COSYVOICE_PATH, 'pretrained_models', 'CosyVoice2-0.5B')

# æ¨¡å‹å®ä¾‹(å»¶è¿Ÿåˆå§‹åŒ–)
cosyvoice = None
client = OpenAI(api_key=OPENAI_API_KEY, base_url=OPENAI_BASE_URL)


# ============= è¯­éŸ³åˆæˆæ¨¡å— =============

def load_model():
    """å»¶è¿ŸåŠ è½½CosyVoice2æ¨¡å‹ï¼Œé¿å…åœ¨å¯¼å…¥æ—¶å°±åŠ è½½å¤§æ¨¡å‹"""
    global cosyvoice
    if cosyvoice is None:
        try:
            print(f"æ­£åœ¨åŠ è½½CosyVoice2æ¨¡å‹ï¼Œè·¯å¾„: {COSYVOICE_MODEL_PATH}")
            cosyvoice = CosyVoice2(
                COSYVOICE_MODEL_PATH,
                load_jit=False,
                load_trt=False,
                fp16=False,
                use_flow_cache=False
            )
            print("CosyVoice2æ¨¡å‹åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"åŠ è½½CosyVoice2æ¨¡å‹å¤±è´¥: {e}")
            return None
    return cosyvoice


def synthesize_voice(script: str, voice_audio_path: str, prompt_text: str) -> Tuple[int, List[str]]:
    """
    ä½¿ç”¨CosyVoice 2åˆæˆå£°éŸ³ã€‚
    
    Args:
        script: è¦æœ—è¯»çš„æ•…äº‹æ–‡æœ¬
        voice_audio_path: å‚è€ƒå£°éŸ³éŸ³é¢‘æ–‡ä»¶çš„è·¯å¾„
        prompt_text: å‚è€ƒéŸ³é¢‘çš„æ–‡æœ¬å†…å®¹
        
    Returns:
        Tuple of (status_code, [list_of_audio_paths])
    """
    try:
        # åŠ è½½æ¨¡å‹
        model = load_model()
        if model is None:
            return (500, ["æ— æ³•åŠ è½½CosyVoice2æ¨¡å‹"])
        
        # åŠ è½½å‚è€ƒéŸ³é¢‘
        prompt_speech_16k = load_wav(voice_audio_path, 16000)
        
        # å°†è„šæœ¬åˆ†æ®µ
        # æŒ‰å¥å·ã€é—®å·ã€æ„Ÿå¹å·åˆ†å‰²ï¼Œæ”¯æŒä¸­è‹±æ–‡æ ‡ç‚¹
        sentences = []
        current = ""
        for char in script:
            current += char
            if char in ["ã€‚", "ï¼", "ï¼Ÿ", ".", "!", "?"]:
                if current.strip():
                    sentences.append(current.strip())
                current = ""
        if current.strip():
            sentences.append(current.strip())
        
        # ä¸ºäº†æ–¹ä¾¿ç®¡ç†ç”Ÿæˆçš„æ–‡ä»¶ï¼Œåˆ›å»ºä¸€ä¸ªä¸´æ—¶ç›®å½•
        temp_dir = tempfile.mkdtemp()
        output_paths = []
        
        # ç”ŸæˆéŸ³é¢‘
        for idx, sentence in enumerate(sentences):
            # ä½¿ç”¨zero_shotæ¨¡å¼åˆæˆ
            results = model.inference_zero_shot(
                sentence, prompt_text, prompt_speech_16k, stream=False
            )
            for i, result in enumerate(results):
                output_path = os.path.join(temp_dir, f'story_part_{idx}_{i}.wav')
                torchaudio.save(output_path, result['tts_speech'], model.sample_rate)
                output_paths.append(output_path)
        
        return (200, output_paths)
    
    except Exception as e:
        import traceback
        error_msg = f"å£°éŸ³åˆæˆæ—¶å‡ºé”™: {str(e)}\n{traceback.format_exc()}"
        return (500, [error_msg])


def combine_audio_files(file_paths: List[str]) -> Optional[str]:
    """å°†å¤šä¸ªéŸ³é¢‘æ–‡ä»¶åˆå¹¶ä¸ºä¸€ä¸ª"""
    if not file_paths:
        return None
    
    # åˆ›å»ºè¾“å‡ºæ–‡ä»¶è·¯å¾„
    output_path = tempfile.mktemp(suffix='.wav')
    
    # è¯»å–æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶
    waves = []
    sample_rate = None
    for path in file_paths:
        waveform, sr = torchaudio.load(path)
        if sample_rate is None:
            sample_rate = sr
        elif sample_rate != sr:
            # å¦‚æœé‡‡æ ·ç‡ä¸åŒï¼Œéœ€è¦é‡é‡‡æ ·
            resampler = torchaudio.transforms.Resample(sr, sample_rate)
            waveform = resampler(waveform)
        waves.append(waveform)
    
    # æ‹¼æ¥æ‰€æœ‰éŸ³é¢‘
    combined = torch.cat(waves, dim=1)
    
    # ä¿å­˜åˆå¹¶åçš„éŸ³é¢‘
    torchaudio.save(output_path, combined, sample_rate)
    
    return output_path


# ============= æ•…äº‹ç”Ÿæˆæ¨¡å— =============

def generate_script(story_plot: str) -> str:
    """ä½¿ç”¨LLMç”Ÿæˆæ•…äº‹è„šæœ¬"""
    if not story_plot.strip():
        return "è¯·å…ˆè¾“å…¥æ•…äº‹æƒ…èŠ‚ï¼"
    
    try:
        response = client.chat.completions.create(
            model=OPENAI_MODEL_NAME,
            messages= [
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€åå¯Œæœ‰ç»éªŒçš„å„¿ç«¥æ–‡å­¦ä½œè€…å…¼æ•™è‚²ä¸“å®¶ï¼Œä¸“ç²¾äºç”¨ç®€æ´æ˜äº†ã€å……æ»¡è¶£å‘³çš„è¯­è¨€ç¼–å†™å…¼å…·å¯å‘æ€§å’Œå¨±ä¹æ€§çš„æ•…äº‹ã€‚"
                },
                {
                    "role": "user",
                    "content": f"è¯·åŸºäºæä¾›çš„æ•…äº‹æƒ…èŠ‚ï¼Œä¸ºå­©å­ä»¬åˆ›ä½œä¸€åˆ™é€‚åˆä¸ªäººè®²è¿°çš„ç²¾å½©æ•…äº‹ï¼š{story_plot}ã€‚ç¡®ä¿æ•…äº‹ä¸ä»…èƒ½å¤Ÿå¸å¼•å°æœ‹å‹çš„å…´è¶£ï¼Œè¿˜èƒ½ä¼ é€’ç§¯ææ­£é¢çš„ä¿¡æ¯å’Œä»·å€¼è§‚ã€‚"
                }
            ],
            temperature=0.7,
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"ç”Ÿæˆæ•…äº‹æ—¶å‡ºé”™: {str(e)}"


def update_script_status(script: str) -> str:
    """æ›´æ–°æ•…äº‹è„šæœ¬çŠ¶æ€"""
    if not script or script == "è¯·å…ˆè¾“å…¥æ•…äº‹æƒ…èŠ‚ï¼" or script.startswith("ç”Ÿæˆæ•…äº‹æ—¶å‡ºé”™"):
        return "è¯·å…ˆç”Ÿæˆæ•…äº‹"
    return "æ•…äº‹å·²ç¡®è®¤! ç°åœ¨æ‚¨å¯ä»¥è¿›å…¥æ­¥éª¤2è¿›è¡ŒéŸ³è‰²å…‹éš†"


# ============= åº”ç”¨æµç¨‹æ§åˆ¶ =============

def process_audio_and_generate(
    audio_path: str,
    prompt_text: str,
    script: str
) -> Generator[Tuple[str, Optional[str]], None, None]:
    """
    ç»Ÿä¸€å¤„ç†ä¸Šä¼ æˆ–å½•åˆ¶çš„éŸ³é¢‘ï¼Œè¿›è¡ŒéŸ³è‰²å…‹éš†å¹¶ç”Ÿæˆæ•…äº‹éŸ³é¢‘ã€‚
    """
    synthesis_result = []
    
    try:
        # 1. è¾“å…¥éªŒè¯
        yield "æ£€æŸ¥è¾“å…¥...", None
        if not audio_path or not os.path.exists(audio_path):
            yield "é”™è¯¯ï¼šæœªæä¾›æœ‰æ•ˆéŸ³é¢‘ã€‚", None
            return

        if not prompt_text.strip():
            yield "é”™è¯¯ï¼šPrompt æ–‡æœ¬ä¸èƒ½ä¸ºç©ºã€‚", None
            return

        script_state = update_script_status(script)
        if "è¯·å…ˆç”Ÿæˆæ•…äº‹" in script_state:
            yield "é”™è¯¯ï¼šæ•…äº‹æœªå‡†å¤‡å¥½ã€‚", None
            return

        # 2. è°ƒç”¨è¯­éŸ³åˆæˆ
        yield "æ­£åœ¨è¿›è¡Œå£°éŸ³åˆæˆ...", None
        synthesis_status, synthesis_result = synthesize_voice(script, audio_path, prompt_text)
        
        if synthesis_status != 200:
            error_msg = synthesis_result[0] if synthesis_result else "æœªçŸ¥åˆæˆé”™è¯¯"
            yield f"é”™è¯¯ï¼š{error_msg}", None
            return

        audio_segment_paths = synthesis_result
        if not audio_segment_paths:
            yield "è­¦å‘Šï¼šæœªç”ŸæˆéŸ³é¢‘ç‰‡æ®µã€‚", None
            return

        # 3. åˆå¹¶éŸ³é¢‘ç‰‡æ®µ
        yield f"åˆæˆæˆåŠŸ {len(audio_segment_paths)} ä¸ªç‰‡æ®µï¼Œæ­£åœ¨åˆå¹¶...", None
        combined_audio_path = combine_audio_files(audio_segment_paths)

        if not combined_audio_path or not os.path.exists(combined_audio_path):
            yield "é”™è¯¯ï¼šåˆå¹¶éŸ³é¢‘å¤±è´¥ã€‚", None
            return

        # 4. æˆåŠŸè¿”å›
        yield "æ•…äº‹éŸ³é¢‘ç”ŸæˆæˆåŠŸï¼", combined_audio_path

    except Exception as e:
        import traceback
        error_msg = f"å¤„ç†éŸ³é¢‘æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {str(e)}"
        print(f"{error_msg}\n{traceback.format_exc()}")
        yield f"ä¸¥é‡é”™è¯¯: {error_msg}", None

    finally:
        # 5. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        # æ¸…ç†åˆæˆè¿‡ç¨‹ä¸­åˆ›å»ºçš„ç‰‡æ®µæ–‡ä»¶ç›®å½•
        if synthesis_result and isinstance(synthesis_result, list) and synthesis_result:
            temp_dir = os.path.dirname(synthesis_result[0])
            if temp_dir and os.path.exists(temp_dir) and temp_dir.startswith(tempfile.gettempdir()):
                try:
                    shutil.rmtree(temp_dir)
                    print(f"å·²æ¸…ç†ä¸´æ—¶ç›®å½•: {temp_dir}")
                except Exception as cleanup_e:
                    print(f"æ¸…ç†ä¸´æ—¶ç›®å½•æ—¶å‡ºé”™ {temp_dir}: {cleanup_e}")


# ============= Gradio ç•Œé¢ =============

def create_gradio_interface():
    """åˆ›å»ºGradioç•Œé¢"""
    with gr.Blocks(title="AIæœ‰å£°æ•…äº‹", theme=gr.themes.Soft()) as app:
        gr.Markdown("# ğŸ™ï¸ AIæœ‰å£°æ•…äº‹")
        gr.Markdown("è¿™ä¸ªåº”ç”¨å¯ä»¥å¸®æ‚¨è‡ªåŠ¨ç”Ÿæˆæ•…äº‹å¹¶ç”¨æ‚¨çš„å£°éŸ³æ¥è®²è¿°")

        # å°è¯•æ‰¾åˆ°å›¾ç‰‡
        image_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), "assets", "reading-story-at-home-together.jpg")
        if os.path.exists(image_path):
            gr.Image(image_path,
                     label="æ¬¢è¿ä½¿ç”¨AIæœ‰å£°æ•…äº‹",
                     interactive=False,
                     height=200)

        gr.Markdown("---")

        with gr.Tab("æ­¥éª¤ 1: ç”Ÿæˆæ•…äº‹"):
            gr.Markdown("""
            ### ä½¿ç”¨è¯´æ˜:
            1. åœ¨ä¸‹é¢çš„æ–‡æœ¬æ¡†ä¸­è¾“å…¥æ•…äº‹çš„åŸºæœ¬æƒ…èŠ‚ã€‚
            2. ç‚¹å‡» **"ç”Ÿæˆæ•…äº‹"** æŒ‰é’®ã€‚
            3. æ£€æŸ¥ä¸‹æ–¹ç”Ÿæˆæ•…äº‹ï¼Œå¦‚æœæ»¡æ„ï¼Œç‚¹å‡» **"ä½¿ç”¨ç”Ÿæˆçš„å†…å®¹"** æŒ‰é’®ã€‚
            4. ç¡®è®¤æ•…äº‹åï¼Œè¯·åˆ‡æ¢åˆ° **"æ­¥éª¤ 2: éŸ³è‰²å…‹éš†ä¸è®²è¿°"** é€‰é¡¹å¡ã€‚
            """)

            story_plot = gr.Textbox(
                label="æ•…äº‹æƒ…èŠ‚",
                placeholder="è¯·è¾“å…¥æ•…äº‹çš„åŸºæœ¬æƒ…èŠ‚ï¼Œä¾‹å¦‚ï¼š'å°å…”å­å’Œå°æ¾é¼ åœ¨æ£®æ—é‡Œæ‰¾åˆ°äº†ä¸€ä¸ªç¥å¥‡çš„å®ç®±...'"
            )
            generate_btn = gr.Button("ç”Ÿæˆæ•…äº‹", variant="primary")
            script_output = gr.Textbox(
                label="ç”Ÿæˆæ•…äº‹",
                lines=10,
                placeholder="ç”Ÿæˆæ•…äº‹å°†æ˜¾ç¤ºåœ¨è¿™é‡Œ..."
            )
            confirm_script_btn = gr.Button("ä½¿ç”¨ç”Ÿæˆçš„å†…å®¹")
            script_status = gr.Textbox(label="æ•…äº‹çŠ¶æ€", value="è¯·å…ˆç”Ÿæˆæ•…äº‹", interactive=False)

            # è¿æ¥äº‹ä»¶
            generate_btn.click(fn=generate_script, inputs=story_plot, outputs=script_output)
            confirm_script_btn.click(fn=update_script_status, inputs=[script_output], outputs=[script_status])

        with gr.Tab("æ­¥éª¤ 2: éŸ³è‰²å…‹éš†ä¸è®²è¿°"):
            gr.Markdown("""
            ### ä½¿ç”¨è¯´æ˜:
            1. åœ¨ä¸‹æ–¹åŒºåŸŸï¼Œæ‚¨å¯ä»¥ **ä¸Šä¼ ** ä¸€ä¸ªåŒ…å«æ‚¨å£°éŸ³çš„éŸ³é¢‘æ–‡ä»¶ï¼ˆå¦‚ .wav, .mp3ï¼‰ï¼Œæˆ–è€…ç›´æ¥ç‚¹å‡» **éº¦å…‹é£å›¾æ ‡** å½•åˆ¶æ‚¨çš„å£°éŸ³ã€‚
            2. åœ¨ **"Promptæ–‡æœ¬"** æ¡†ä¸­è¾“å…¥æ‚¨åœ¨éŸ³é¢‘ä¸­è¯´çš„ **ç¡®åˆ‡** å†…å®¹ã€‚**è¿™å¿…é¡»ä¸éŸ³é¢‘å†…å®¹å®Œå…¨åŒ¹é…ï¼**
            3. ç‚¹å‡» **"ä½¿ç”¨æä¾›çš„éŸ³é¢‘ç”Ÿæˆæ•…äº‹"** æŒ‰é’®ã€‚
            4. ç­‰å¾…ç³»ç»Ÿå®ŒæˆéŸ³è‰²å…‹éš†å’Œæ•…äº‹éŸ³é¢‘çš„åˆæˆã€‚
            5. ç”Ÿæˆå®Œæˆåï¼Œæ‚¨å¯ä»¥åœ¨æœ¬é¡µé¢åº•éƒ¨æ’­æ”¾æˆ–ä¸‹è½½æœ€ç»ˆçš„æ•…äº‹éŸ³é¢‘ã€‚

            #### æ³¨æ„:
            * éŸ³é¢‘è´¨é‡è¶Šå¥½ï¼ˆæ¸…æ™°ã€æ— å™ªéŸ³ï¼‰ï¼Œåˆæˆæ•ˆæœè¶Šä½³ã€‚
            * éŸ³é¢‘å†…å®¹ä¸ **"Promptæ–‡æœ¬"** å¿…é¡» **ä¸¥æ ¼ä¸€è‡´**ã€‚
            * å»ºè®®éŸ³é¢‘æ—¶é•¿åœ¨ **5-15ç§’** ä¹‹é—´ã€‚
            """)

            audio_input = gr.Audio(
                sources=["upload", "microphone"],
                type="filepath",
                label="ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶æˆ–ç‚¹å‡»éº¦å…‹é£å½•åˆ¶"
            )
            prompt_text_audio = gr.Textbox(
                label="Promptæ–‡æœ¬ (éŸ³é¢‘ä¸­çš„ç¡®åˆ‡å†…å®¹)",
                placeholder="è¯·è¾“å…¥æ‚¨åœ¨ä¸Šä¼ æˆ–å½•åˆ¶éŸ³é¢‘ä¸­æ‰€è¯´çš„ç¡®åˆ‡å†…å®¹...",
                lines=3
            )
            gen_btn_process = gr.Button("ä½¿ç”¨æä¾›çš„éŸ³é¢‘ç”Ÿæˆæ•…äº‹", variant="primary")

            gr.Markdown("---")

            status_output = gr.Textbox(
                label="ç”ŸæˆçŠ¶æ€",
                placeholder="ç”Ÿæˆè¿‡ç¨‹çš„çŠ¶æ€å°†æ˜¾ç¤ºåœ¨è¿™é‡Œ...",
                interactive=False
            )
            final_audio = gr.Audio(label="ç”Ÿæˆçš„æ•…äº‹éŸ³é¢‘")

            # è¿æ¥äº‹ä»¶
            gen_btn_process.click(
                fn=process_audio_and_generate,
                inputs=[audio_input, prompt_text_audio, script_output],
                outputs=[status_output, final_audio]
            )

    return app


# ============= ç¨‹åºå…¥å£ =============

if __name__ == "__main__":
    # æ£€æŸ¥CosyVoiceæ˜¯å¦å·²ç»æ­£ç¡®å¯¼å…¥
    if 'cosyvoice' not in sys.modules:
        print("è­¦å‘Š: CosyVoiceæ¨¡å—æœªæ­£ç¡®å¯¼å…¥ï¼Œåº”ç”¨å¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œ")
        print(f"è¯·ç¡®ä¿å·²å…‹éš†CosyVoiceåº“åˆ°: {COSYVOICE_PATH}")
        sys.exit(1)
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(COSYVOICE_MODEL_PATH):
        print(f"è­¦å‘Š: CosyVoiceæ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œè¯·ç¡®ä¿ä¸‹è½½æ¨¡å‹åˆ°: {COSYVOICE_MODEL_PATH}")
        print("ä¸‹è½½å‘½ä»¤: git clone https://www.modelscope.cn/iic/CosyVoice2-0.5B.git pretrained_models/CosyVoice2-0.5B")
        print("ç»§ç»­è¿è¡Œï¼Œä½†è¯­éŸ³åˆæˆåŠŸèƒ½å¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œ")
    
    # å¯åŠ¨Gradioåº”ç”¨
    app = create_gradio_interface()
    app.launch()